{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f17c26ef5290d45b564a2185541d945",
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2018) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "17637116f0218346c06c2323a22e47ec",
     "grade": false,
     "grade_id": "h01",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "31dfe860c9b0c3315e77c89c7ab0133c",
     "grade": false,
     "grade_id": "h02",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Sunday, July 1, 2018**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6038c34635e11b998ecee2321dfb51fe",
     "grade": false,
     "grade_id": "ex11",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assignment 1: Temporal probability models [4 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "33e0733b78ec8c78295a89deeb144d4d",
     "grade": false,
     "grade_id": "ex11a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Hidden Markov Model\n",
    "\n",
    "Explain the structure of a Hidden Markov Model. What probabilities have to be provided for such a model and how can they be specified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e8c42a6bb86eb611bf10e6b20b2cf754",
     "grade": true,
     "grade_id": "ex11a_solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A Hidden Markov Model is a Markov process using a single variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "468482032a43d51656f6adf9f403d625",
     "grade": false,
     "grade_id": "ex11b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Inference tasks\n",
    "\n",
    "What is the goal of most likely explanation? Why is the most likely sequence not the sequence of the most likely states? Give an example where these two sequences disagree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c46702e30a7b509cfb9cc449e0fb8c88",
     "grade": true,
     "grade_id": "ex11b_solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fdc851273255408edb3789edf409ae52",
     "grade": false,
     "grade_id": "ex11c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Speech recognition\n",
    "\n",
    "Summarize in you own words the approach to speech recognition presented in the lecture. Explain what kind of inference problems occur and how they are solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad6c1de8e53cea99a7b8689ce2307883",
     "grade": true,
     "grade_id": "ex11c_solution",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ae3409696cab0d9713472be2a42b8215",
     "grade": false,
     "grade_id": "ex2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assignment 2: Implementing HMM [6 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c0d41c0d08c21795fce5ea8f0dd10cf5",
     "grade": false,
     "grade_id": "ex2a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**a)** Implement the basic inference algorithms for HMMs. You may do so by filling in the stubs in the following class. In this implementation, we represent finite probability distributions as one-dimensional numpy arrays, with values summing up to one, e.g. the initial state distribution over three stats $a,b,c$ with $P(a)=0.3, P(b)=0.2, P(c)=0.5$ would be represented by the array `[0.3, 0.2, 0.5]`. Transition matrices are realized by two-dimensional arrays.\n",
    "\n",
    "If you prefer to write your own code, you will find an empty code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ef30907527853290253244a9b633a62b",
     "grade": true,
     "grade_id": "cell-e1ef9c034200f6d3",
     "locked": false,
     "points": 4,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM:\n",
    "    \"\"\"A class implementing a Hidden Markov Model. This class provides methods\n",
    "    to perform the standard inference tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, states, outputs, p_initial, p_transition, p_output):\n",
    "        \"\"\"Create a new HMM.\n",
    "        \n",
    "        Args:\n",
    "            states (list): a list a valid states.\n",
    "            outputs (list): a list of valid output symbols.\n",
    "            p_initial (array_like): initial state distribution. Should add up to one.\n",
    "            p_transition (array_like, ndim=2): state transition probabilities.\n",
    "              Each row is a probability distribution over states, should add up to one.\n",
    "            p_output (array_like, ndim=2): output emission probabilities.\n",
    "              Each row is a probability distribution over output values, should add up to one.\n",
    "        \"\"\"\n",
    "        self.states = states\n",
    "        self.outputs = outputs\n",
    "        self.p_initial = np.asarray(p_initial)\n",
    "        self.p_transition = np.asarray(p_transition)\n",
    "        self.p_output = np.asarray(p_output)\n",
    "        \n",
    "        # Some sanity checks\n",
    "        assert self.p_initial.shape == (len(self.states),), \"Invalid shape for initial state distribution.\"\n",
    "        assert self.p_initial.sum() == 1.0, \"Initial state probabilities do not add up to one.\"\n",
    "        assert self.p_transition.shape == (len(self.states),len(self.states)), \"Invalid shape for state transition table.\"\n",
    "        assert np.all(np.equal(self.p_transition.sum(axis=1),1.0)), \"State transition probabilities do not add up to one.\"\n",
    "        assert self.p_output.shape == (len(self.states),len(self.outputs)), \"Invalid shape for emission table.\"\n",
    "        assert np.all(np.equal(self.p_output.sum(axis=1),1.0)), \"Emission probabilities do not add up to one.\"\n",
    "\n",
    "    \n",
    "    def prediction(self, p_states):\n",
    "        \"\"\"Compute a prediction step, i.e. from a given\n",
    "        state distribution P(X_{t}), compute the next\n",
    "        state distribution P(X_{t+1}).\n",
    "        \n",
    "        Args:\n",
    "            p_states (ndarray): the current state distribution.\n",
    "            \n",
    "        Retuns:\n",
    "            ndarray: the probability distribution for the next state.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def forward(self, p_states, observation):\n",
    "        \"\"\"Compute a forward step, i.e. from a given\n",
    "        state distribution P(X_{t}), and an observation\n",
    "        e_{t+1} compute the next state distribution\n",
    "        P(X_{t+1}).\n",
    "        \n",
    "        Args:\n",
    "            observation: The next observation.\n",
    "            \n",
    "        Retuns:\n",
    "            The probability distribution\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def backward(self, p_observations, observation):\n",
    "        \"\"\"Compute a backward step, i.e. from a given\n",
    "        output distribution P(e_{t+2,T}|X_{t+1}) and an\n",
    "        observation e_{t+1} compute the next previous\n",
    "        output distribution P(e_{t+1,T}|X_{t}).\n",
    "        \n",
    "        Args:\n",
    "            observation: The next observation.\n",
    "            \n",
    "        Retuns:\n",
    "            The probability distribution\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def filtering(self, observations):\n",
    "        \"\"\"Filter this sequence, i.e., iteratively\n",
    "        determine the state probabilities given an \n",
    "        observed output sequence.\n",
    "    \n",
    "        Args:\n",
    "            observations (list): The sequence of observations.\n",
    "\n",
    "        Returns:\n",
    "            list of ndarray: A sequence of state probability\n",
    "            distributions.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def smoothing(self, observations, k):\n",
    "        \"\"\"The forward-backward algorithm to determine a state \n",
    "        distribution based on past and future observations.\n",
    "        \n",
    "        Args:\n",
    "            observations (list): The sequence of observations.\n",
    "            k (int): The index for which to determine the state\n",
    "            probabilities.\n",
    "\n",
    "        Returns:\n",
    "            ndarray: the state probability distributions for the\n",
    "            given index k.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "\n",
    "    def viterbi(self, observations):\n",
    "        \"\"\"The Viterbi algorithm. Determine the most likely sequence\n",
    "        of hidden states, given an observed output sequence.\n",
    "    \n",
    "        Args:\n",
    "            observations (list): The sequence of observations.\n",
    "\n",
    "        Returns: two return values:\n",
    "            1. list: the most likely sequence of states\n",
    "            2. list of ndarray: A sequence of probability vectors,\n",
    "            providing for each time t and state s the probability\n",
    "            of the most likely initial sequence ending in that state.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        return sequence, P_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e5e41eae8be282101b98b6395c406edb",
     "grade": true,
     "grade_id": "cell-acdc454891a6cfab",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# If you prefer to do your own implementation, place your code here ...\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6757e3085c93bffe25fa459002d73ff6",
     "grade": false,
     "grade_id": "cell-075ef0a8accd8b7b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**The umbrella example**\n",
    "\n",
    "The following cell initializes a HMM based on the example from the lecture (ML-12 slide 13ff). Use the cells below to check your implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values of the hidden states\n",
    "states = ['rain','sun']\n",
    "\n",
    "# The possible output values\n",
    "outputs = [True, False]\n",
    "\n",
    "\n",
    "# The initial distribution of states\n",
    "initial = [0.5, 0.5]\n",
    "\n",
    "# The state transition table\n",
    "transition = [[0.7, 0.3],\n",
    "              [0.3, 0.7]]\n",
    "\n",
    "# The output probabilities for each state\n",
    "output = [[0.9,0.1],\n",
    "          [0.2,0.8]]\n",
    "\n",
    "model = HMM(states, outputs, initial, transition, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the filtering example from the lecture (ML-12 slide 16)\n",
    "\n",
    "observations = [True,True]\n",
    "P = model.filtering(observations)\n",
    "\n",
    "assert np.allclose(P[0], [0.500, 0.500], rtol=5e-2), \"Bad initial distribution for filtering.\"\n",
    "assert np.allclose(P[1], [0.818, 0.182], rtol=5e-2), \"Bad filter values (step 1).\"\n",
    "assert np.allclose(P[2], [0.883, 0.117], rtol=5e-2), \"Bad filter values (step 2).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the smoothing example from the lecture (ML-12 slide 21)\n",
    "\n",
    "observations = [True,True]\n",
    "\n",
    "assert np.allclose(model.smoothing(observations,1), [0.883, 0.117], rtol=5e-2), \"Bad smoothing result (k=1)\"\n",
    "assert np.allclose(model.smoothing(observations,2), [0.883, 0.117], rtol=5e-2), \"Bad smoothing result (k=2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the most likely explanation example from the lecture (ML-12 slide 24)\n",
    "\n",
    "observations = [True,True,False,True,True]\n",
    "most_likely_sequence, P_max = model.viterbi(observations)\n",
    "\n",
    "assert [model.states[s] for s in most_likely_sequence] == ['rain', 'rain', 'sun', 'rain', 'rain'], \"Wrong sequence (Viterbi)\"\n",
    "assert np.allclose(P_max[0], [0.8182, 0.1818], rtol=5e-2), \"Bad viterbi (step 0).\"\n",
    "assert np.allclose(P_max[1], [0.5155, 0.0491], rtol=5e-2), \"Bad viterbi (step 1).\"\n",
    "assert np.allclose(P_max[2], [0.0361, 0.1237], rtol=5e-2), \"Bad viterbi (step 2).\"\n",
    "assert np.allclose(P_max[3], [0.0334, 0.0173], rtol=5e-2), \"Bad viterbi (step 3).\"\n",
    "assert np.allclose(P_max[4], [0.0210, 0.0024], rtol=5e-2), \"Bad viterbi (step 4).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48f0c283c45679009b82b7f67decc0b5",
     "grade": false,
     "grade_id": "ex2b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**b)** Now use your implementation to study the behaviour of such a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c8f1f4db3a59070b3753aa2d896e4ab3",
     "grade": false,
     "grade_id": "ex2b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**1.** Run your model to predict the state distributions without providing any output evidence, i.e. only use the state transition matrix. What do you observe? How does the behavior change if you provide another initial distribution? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "52a799f3cbfc6eaaef84b98bf84a7973",
     "grade": true,
     "grade_id": "ex2b1-solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da67dd4cf74f09effc7b4fd00dda11a6",
     "grade": true,
     "grade_id": "ex2b1-solution-text",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cc1227e7d91ede6f7133694f56f7d88f",
     "grade": false,
     "grade_id": "ex2b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**2.** Drive your model by providing some observations. Compare the sequence of most likely states with the most likely sequence of states. Can you provide a case where these are different for the \"umbrella\" model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0a29106b3e5cc722238e27c15c1c0ec3",
     "grade": true,
     "grade_id": "ex2b2-solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "99b375a7e2fef671a53f7a8c9ac87276",
     "grade": true,
     "grade_id": "ex2b2-solution-text",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b5b89fbaa3fca39dd0be4bebb6c66fd",
     "grade": false,
     "grade_id": "recap2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Recap (part II)\n",
    "\n",
    "This is the second part of the recap material. These exercises do not need to be solved in order to qualify for the final exam but it is highly recommended for preparation. Also if you hit any question that should be discussed in more detail, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6cf2bdd2aaeae941450b202c16466b40",
     "grade": false,
     "grade_id": "r06",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 6: Neural Networks [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3de6953a83ac01bf99e492bca3f62693",
     "grade": false,
     "grade_id": "r06a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Neural Networks\n",
    "\n",
    "Name three different kinds of Artificial Neural Networks discussed in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2431e920e06b6e2975f02f70b736cbe1",
     "grade": true,
     "grade_id": "r06a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Multilayer Perceptron\n",
    "2. Self-Organizing Maps\n",
    "3. Radial Basis Function Network \n",
    "4. Recurrent Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a66ab87c34b88f7d75630775c1acb98",
     "grade": false,
     "grade_id": "r06b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Backpropagation\n",
    "\n",
    "Which of the following formulae describes the backpropagation of the error through hidden layers in a Multilayer Perceptron?\n",
    "Assume they are calculated for each $k=L_H \\dots 1$ and $i=1\\dots N(k)$.\n",
    "\n",
    "1. $\\delta_i(k) = f^\\prime(o_i(k)) \\sum\\limits_{j=1}^{N(k+1)} w_{ji}(k+1, k)o_j(k)$\n",
    "2. $\\delta_i(k) = f^\\prime(o_i(k)) \\sum\\limits_{j=1}^{N(k+1)} w_{ji}(k+1, k)\\delta_j(k+1)$\n",
    "3. $\\delta_i(k) = f^\\prime(o_i(k)) \\sum\\limits_{j=1}^{N(k+1)} w_{ji}(k, k-1)\\delta_j(k+1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "16efb9c9bc8a9da51eb891cebcc310e7",
     "grade": true,
     "grade_id": "r06b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The second formula accurately describes backpropagration for a MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8b2383196240f8015fce8111c44618c7",
     "grade": false,
     "grade_id": "r06c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Hebb's rule\n",
    "Explain Hebb's rule. Provide a formula. What is the relation to Oja's rule?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "664e40dd0aed7acfe1360fc06d9464d9",
     "grade": true,
     "grade_id": "r06c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Hebb's rule models the adaption of neurons during learning and can also be used in neural networks to adapt the weights of the neurons in order to learn a target function. The weight between two increases when they fire together. Hebb's rule is calculated by\n",
    "$$\\Delta w_i = \\varepsilon\\cdot(\\vec{x}\\cdot\\vec{y})x_i$$\n",
    "where $\\varepsilon$ is the learning rate. A problem with Hebb's rule is that weights can become arbitrarily large, since they are never *unlearned*, e.g. weights don't decrease. This can be fixed by applying Oja's Rule, which includes a **weight decay** term, that makes it so that the weights of neuron's that don't fire anymore are decreased over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "af1564b6767d050589c7ff767121c17a",
     "grade": false,
     "grade_id": "r07",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 7: Local Methods [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f90b47c72735d7628fb7ec7cf3bc623",
     "grade": false,
     "grade_id": "r07a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Local methods\n",
    "\n",
    "What are differences between local and global methods? What are advantages or disadvantages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7b04430591b527b08dcf411dc922e1d7",
     "grade": true,
     "grade_id": "r07a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Local methods are local in respect to the input space, so the output is calculated independently for different regions of the input space, meaning that changes in one region don't affect the output of other regions.  \n",
    "In contrast, when using global methods, a single example may influence the performance of the complete method for any other example.\n",
    "\n",
    "|        | Advantages | Disadvantages |\n",
    "| -----  | ---------- | ------------- |\n",
    "| local  | easier to manage parameters | can get stuck in local extrema |\n",
    "|        | usually more robust | |\n",
    "| global | can learn more complex models | overall performance may decrease due to a single example |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "69286c3f3433fc504bba0b3a6789b322",
     "grade": false,
     "grade_id": "r07b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) MLP and RBFN\n",
    "\n",
    "Is an MLP or are RBFN local methods? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "caacbd38edeb60e5cb2fd5fa56098c01",
     "grade": true,
     "grade_id": "r07b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A MLP is not local, the overall error of the network is used to update the weights of all neurons. A RBFN is local, because each neuron is a local function which may or may not be modified by an example and therefore changes only have local effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1415431834f79d0e1243bbafb7570b16",
     "grade": false,
     "grade_id": "r07c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c)  Nearest neighbor\n",
    "\n",
    "How does the nearest neighbor approach work? How can it be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6f85205012c26449e35a517cdf9f9918",
     "grade": true,
     "grade_id": "r07c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The nearest neighbour approach stores all input examples and matches previously unseen data to the *nearest* stored example. For example, I could have a (somewhat dumb) training dataset containing 3 examples, each belonging to a different class. Now, for all new data, I look at my 3 stored examples and calculate the distance from my new data point to each of those. Then I simply choose the *nearest* (depends on the metric used) and output the class of the nearest neighbour as the class of the new data point.  \n",
    "\n",
    "This classifier can be improved by not only choosing 1 neighbour, but rather a fixed amount of *k* neighbours, and then, depending on whether my output is discrete or real, I can deduct the output:\n",
    "* **discrete**: choose the most occuring class (if there is a tie, toss a coin)\n",
    "* **real**: calculate the mean of all *k* neighbours\n",
    "\n",
    "This adaption is called *K-nearest neighbour* (or neighbor if you prefer American English)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9fa96aacb39ac35cf406e6ccc018d70e",
     "grade": false,
     "grade_id": "r08",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 8: Classification [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2abe8e72e4c19c2e40830204a9d8a688",
     "grade": false,
     "grade_id": "r08a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Classfier\n",
    "\n",
    "What is a classifier? What is the relation to a concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "50c9a68e3b8b1306c2181af7ab6d8fec",
     "grade": true,
     "grade_id": "r08a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A classifier is an algorithm (of some kind) that assigns one class of a finite set of classes to a specific instance. The relation to a concept can be made clear quite easily, because a classifier with only 2 classes *IsACar* and *IsNotACar* is pretty much the same as a concept, which is a binary function saying whether an example is an instance of a specific concept or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c5b630f3827ca3bf0d814cb58281196e",
     "grade": false,
     "grade_id": "r08b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Comparison of classifiers\n",
    "\n",
    "Name three different classifiers and compare them. Think about biases and assumptions, separatrices, sensitivity, locality, parameters and speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c755dd1b956540416bb8f3c924768b90",
     "grade": true,
     "grade_id": "r08b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **LDA**$^1$\n",
    "    * bias\n",
    "        * identical a priori probability for all classes\n",
    "        * all classes exhibvit a Gaussian distribution with equal means and covariances\n",
    "    * linear separatrix, explicitly represented\n",
    "    * Global\n",
    "    * Sensitive to far outliers\n",
    "    * No Parameters needed\n",
    "    * Fast (training)\n",
    "* **Nearest-neighbour**\n",
    "    * distance in input space is equal to distance in output space\n",
    "    * implicitly defined linear separatrix\n",
    "    * local (as discussed previously)\n",
    "    * No sensitivities\n",
    "    * No parameters\n",
    "    * Fast (trainint) speed (but needs lots of memory) and finding the best matching neighbour can take time\n",
    "* **SVM**$^2$\n",
    "    * only 2 classes\n",
    "    * linear, but can be used to model non-linear separatrix using the *kernel trick*\n",
    "    * local (TODO?)\n",
    "    * usually sensitive to outliers, but an extension can solve that\n",
    "    * No parameters\n",
    "    * Fairly fast\n",
    "\n",
    "---\n",
    "\n",
    "$^1$ *linear discriminant analysis*  \n",
    "$^2$ *support vector machine*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aa0cbd27cac42fa8e37044709288123f",
     "grade": false,
     "grade_id": "ex08c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) SVM\n",
    "\n",
    "What is a support vector? How does the kernel trick work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9f675e71da82dca8138ab125d6ac4309",
     "grade": true,
     "grade_id": "r08c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A support vector is an example/instance that lies on the boundary of the margin (or rather, all suport vectors *make up* the margin) and therefore, they are the instances most hard to classifiy. The kernel trick projects the data to a higher-dimensional space, which makes the problem linearly seperable. That would normally be quite hard to compute, but since a SVM only uses inner products of vectors, the inner product of the data in that higher-dimensional projection can be computed in the original input space using a *kernel function*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7cf62c7d4f666e95481d5e3aa809c039",
     "grade": false,
     "grade_id": "r09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 9: Reinforcement Learning [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "647b504595f55e43ea201d99e66c9663",
     "grade": false,
     "grade_id": "r09a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a)\n",
    "\n",
    "What is an agent in terms of reinforcement learning? Name an example of an agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d48809f1c135c4e99f4e599fd2119511",
     "grade": true,
     "grade_id": "ex09a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "An agent in terms of reinforcement learning is someone that has a state from which he can transition to other states using one of the finite set of possible actions.\n",
    "\n",
    "An agent is defined by:\n",
    "* Performance\n",
    "    * A goal or task to be perfomed by the agents (which may be discrete or real in terms of success)\n",
    "* Environment\n",
    "    * The environment in which the agent acts.\n",
    "* Actuators\n",
    "    * Available actions, control mechanism, *things* which the agent can use to act\n",
    "* Sensors\n",
    "    * Means by which information is aquired\n",
    "    \n",
    "So an agent is a system embedded in an environment, which it explores using its sensors and who can interact with said environment using its actuators (weird word).\n",
    "\n",
    "**Example:** Expert System\n",
    "* Performance\n",
    "    * Answer a query appropriately\n",
    "* Environment\n",
    "    * User, database\n",
    "* Actuators\n",
    "    * Database return value\n",
    "* Sensors\n",
    "    * Query (text or speech input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "213c164ae670eed99688fda7a3b91005",
     "grade": false,
     "grade_id": "r09b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b)\n",
    "\n",
    "What is the Markov assumption? How is it related to Q-learning? Give an example for which it does not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e6411198d475b4cfe3fc65f05aa08116",
     "grade": true,
     "grade_id": "r09b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Markov assumption says that all successor states only depend on the current state of an agent (not earlier ones) and that the same applies to rewards, e.g. the next reward only depends of the current reward. Q-learning employs the Markov assumption, e.g. it only looks at the estimated reward from the current state to the next und uses that to update the value of the current state (and transitions to that next state). In that way, the current state is assumed to hold all information necessary to make a decision.  \n",
    "\n",
    "**Example:**  \n",
    "Suppose you have 1 container filled with 3 balls of which 1 is red and 2 are green. For 3 days, each day 1 ball is drawn (without replacement) from that container. On day 1, a green ball is drawn. On day 2, the other green ball is drawn. Now, under the Markov assumption, you would only know that 1 green ball has been removed, therefore the probability for either a red or a green ball being left are identical ($\\frac{1}{2}$). However, if you know which ball was drawn on the first day, then you know for certain that the red ball is left in the container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "26436207ba7ec4a4ff50cf5278be35ea",
     "grade": false,
     "grade_id": "r09c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) \n",
    "What does the $Q$-function express in reinforcement learning and how is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6f0986ee04fe074aa3f70849e8a1456",
     "grade": true,
     "grade_id": "r09c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The $Q$-function $Q^\\pi(s,a)$ is the action-value function, in other words, it is the expected reward that is received when starting from state $s$ and performing action $a$ under policy $\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b9f933d21a33cae24d41f679c7803209",
     "grade": false,
     "grade_id": "r10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 10: Modeling Uncertainty [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "433d9e2c8d4a489f66e3c1a27a81b22f",
     "grade": false,
     "grade_id": "r10a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Uncertainty\n",
    "\n",
    "Why do we need to model uncertainties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "372f9f0bb419c6ee099547d4f8b43953",
     "grade": true,
     "grade_id": "r10a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are many reasons for which uncertainties can occur, including imprecise technology, high complexity, partially unobervable environments or simply natural uncertainty. Since uncertainty can occur, it is useful to devise strategies to deal with it, in order to be able to produce good models even in the face of uncertainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1cdae0162a25e6912b619666e4e9c2d2",
     "grade": false,
     "grade_id": "ex10b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Naive Bayes\n",
    "\n",
    "What is a naive Bayes classifier? Why is it naive? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dc992a2576b38233208e9a8b6351c1ac",
     "grade": true,
     "grade_id": "r10b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A naive Bayes classifier is a probabilistic classifier that applies Bayes' Theorem to given a priori and conditional probabilities. It is naive because it assumes that all features are independent.\n",
    "\n",
    "If $C$ is a cause and $E_i$ for $i = 1,\\dots n$, are the effects, then\n",
    "\\begin{align*}\n",
    "P(C,E_1, E_2,\\dots, E_n) &= P(E_1 | C,E_2,\\dots,E_n)P(C,E_2,\\dots,E_n)\\\\\n",
    "&= P(E_1 | C,E_2,\\dots,E_n)P(E_2 | C,E_3,\\dots,E_n)P(C,E_3,\\dots,E_n)\\\\\n",
    "&= \\prod_{i=1}^n P(E_i | C) P(C)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "94641b398e85e11fb9e8c44bbd7373b2",
     "grade": false,
     "grade_id": "r10c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Probabilities\n",
    "\n",
    "Given the following table, calculate the probability of drawing a blue candy blindly (assume the bags are chosen equally likely). Then calculate the probability that our drawn blue candy was drawn from the red bag.\n",
    "\n",
    "|                | blue candies | green candies |\n",
    "|----------------|--------------|---------------|\n",
    "| **red bag**    |            5 |            10 |\n",
    "| **yellow bag** |           20 |            10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a3f1a21a2a207eaf763203562914c18c",
     "grade": true,
     "grade_id": "ex10c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\begin{align*}\n",
    "P(b) &= \\frac{1}{2} \\cdot \\frac{1}{3} + \\frac{1}{2} \\cdot \\frac{2}{3}\\\\\n",
    "&= \\frac{1}{2} = 0.5\\\\\n",
    "P(r|b) &= \\frac{P(b|r)P(b)}{P(r)}\\\\\n",
    "&= \\frac{\\frac{1}{3}\\cdot \\frac{1}{2}}{\\frac{1}{2}}\\\\\n",
    "&\\approx \\frac{0.166}{0.5} \\approx 0.0833\n",
    "\\end{align*}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
